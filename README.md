## 一、项目概述

### 项目概念 



在过去两年里，我为一家服装公司负责后台订单系统的开发，其中发现外企的特殊工作流程导致信息处理过于复杂，交流和查询成本巨大，所以尝试性的构建了一个全链路的 agentic 管理机器人，从架构搭建、知识图谱构建、模型选择、到 sft 与 GROP 微调，演示应用和验证，完整走过了 LLM 后训练的全过程。



### 项目介绍


整个项目的技术栈是基于 ToB 的企业后台管理系统，整体架构是前端交互+LLM+知识图谱的智能查询系统。整个系统的流程是这样的：


**1.用户查询 ->** 输入文本查询

**2.Web 终端**：对用户输入进行清洗、意图初筛、模版查询

**3.Agentic（LLM）**：理解用户意图，决定如何回应（直接回答或调用 MCP Toots / Sub Agents），可能调用多个工具

**4.Web终端**：将自然语言回答、邮件模版、总结归纳以后台系统模板化展示

**5.返回给用户 ->** 返回模板化信息



这个流程看起来简单，但挑战在细节中。最大的挑战是高质量信息以准确率的 trade off，因此，如何在高质量信息和准确率之间保持完美的平衡，是整个项目的中心。

最终关键信息比达到90%
因此，在这个项目中，我构建了基于小模型（Qwen2.5-7B）与大模型（Qwen2.5-72B）结合的分层 Agent 架构





## 二、Agent 结构设计

### 2.1 为什么需要分层 Agnet 架构

这个项目最核心的实际就是 Agent 结构。一开始我考虑过视同单一的大模型来处理所有问题，但是很快发现这样不行：

*问题1：响应速度慢*
大模型推理速度慢，用户等待时间长，体验差

*问题2：成本高*
所有请求都用大模型，成本太贵，不可持续

*问题3：灵活性差*

简单查询（如人员信息）和复杂场景（如某款号进度分析）使用相同的模型，资源浪费

所以我设计了一个**双层 Agent 架构**： Orchestrator（协调器） + Sub - Agent

### 2.2 Orchestrator 的设计理念

Orchestrator 是整个系统的大脑，但它不是一个全能的大脑，而是一个聪明的调度员，路由控制。它的核心职责有三个：

- **1.意图识别**：理解用户想要做什么
- **2.任务分发**：决定调用哪个Sub-Agent
- **3.对话管理**：维护上下文，组织语言回复用户

关键的设计点是：**Orchestrator会先用自然语言给用户一个快速反馈，然后再去执行任务。**

- 举个例子：
  - 用户说：「我想知道订单XXX-XXX的负责人员」
  - Orchestrator立即回复：「让我帮你查询一下订单XXX-XXX的负责人员」
  - 然后Orchestrator调用get_user_by_orderID_MCP，去查询订单人员信息
  - 拿到人员信息后，Orchestrator会直接组织语言：「订单XXX-XXX的负责人员都是某某。查询数据来自于后台查询接口，接口负责人员为某某」


- 另一个例子：
  - 用户说：「款号XXX现在是什么进度了」
  - Orchestrator 立即回复：「让我帮你调用信息快速查询下，大概会花费半分钟，请稍等」
  - Orchestrator调用get_orderID_by_styleId_Sub_Agent，去查询款号的订单信息
  - Orchestrator 调用 get_status_by_orderID_MCP，去分析多环节 status，最终给出 summary，返回给 Orchestrator

  - Orchestrator根据summary组织语言：「我完成了调查...款号XXX属于订单XXX，目前的进度已经是成衣工厂处理阶段。查询信息来自于：查询后台接口，接口负责人员为某某，订单状态由知识图谱检索查询，关联到的邮件有 N 件，按时间排序分别为 nALL」

这种"先响应后执行，执行回答和证据一一对应"的设计大大提升了用户体验。首先用户不会觉得系统在发呆，而是知道系统正在处理,其次得到上下文后，进行信息可靠性一一对应。

### 2.3 Sub-Agent/MCP 的分类设计
用户可调用的 MCP tools 分为两类：

1. 简单 MCP Tools

- 处理返回标准查询任务的数据：关系查询、订单历史、订单规划等
- 特点：逻辑简单，API调用固定，不需要复杂推理
- 使用Orchestrator的小模型（Qwen2.5-7B）就能胜任

2. 复杂 Sub-Agent

- 处理复杂诊断任务：订单状态查询、订单进度推进流程、风控问题排查等
- 特点：需要多步推理，可能需要调用多个API，需要根因分析
- 使用大模型（Qwen2.5-72B）

举个复杂 Sub-Agent 的例子：

**场景**：用户说「XXX款货期正常吗」

**处理流程**：

1. Orchestrator 识别意图：XXX款进度判断
2. Orchestrator 先回复：「我帮您查一下，请稍等」
3. 调用get_issue_Sub_Agent（复杂Sub-Agent）
4. Sub-Agent开始分析：
  - 第1步：调用get_order_status_by_styleID API，在订单系统中找到当前款式的所有状态信息
  - 第2步：根据该订单，继续调用get_order_project_by_orderID，查询订单规划的信息内容
  - 第3步：对比规划时间节点和实际时间节点，判断是否正常 
  - 第4步：判断时间节点不符合，进一步调用get_order_all_step_by_orderID 查询所有关联的数据，对话内容
  - 第5步：对所有的关联对话进行评判，发现在样板海外快递运输过程中时间延误，导致延期
  - 第6步：总结根因：样本运往海外工厂的快递延误，导致订单延期
  - Sub-Agent返回诊断结果给Orchestrator
  - Orchestrator组织语言回复用户：「我查到款号XXX属于XXX订单，海外快递过程中延误，导致延期，快递之前时间均符合计划时间。 目前负责人员为某某，上次更新时间为2025-08-24。查询后台接口，接口负责人员为某某，订单状态由知识图谱检索查询，关联到的邮件有 43 件，按时间排序分别为2025-01-01至 2025-08-25，其中正向沟通邮件为 38 件， 负向沟通邮件为 5 件，问题信息来自邮件 主题: 回复: 回复: ASOS -INDOT24846 V2」


这个流程可能涉及5-12步的推理和API调用，需要大模型才能胜任。

### 2.4 跨语言处理策略

在这个项目中，需要语音机器人支持多种语言英语(English)/汉语(Chinese)/服装专业英汉语(Cloth/English/Chinese)，这里有个非常重要的设计：**小模型和大模型的语言能力差异**。

- **Orchestrator**和简单**Sub-Agent**：需要支持Chinese/Cloth-English-Chinese/English，因为要直接跟用户对话
- **复杂Sub-Agent**：只需要支持English，因为它主要是做推理和API调用，而小模型可以调用它的时候将输入翻译成英语

为什么这样设计？

1. **性能考虑**：在prompt中适配大模型支持多语言，导致推理难度更高，推理速度更慢，而复杂Sub-Agent本身就慢，如果再加上多语言负担，延迟会更高
2. **成本考虑**：post-train大模型以使其支持多语言，通常需要更多输入数据，导致训练难度速度更慢，而且质量不稳定
3. **质量考虑**：纯英文的大模型在推理能力上往往更强
所以我们的策略是：

- **小模型（Orchestrator）**：接收用户的Chinese/cloth-Chinese问题，将其转换为英文传递给大模型
- **大模型（复杂Sub-Agent）**：用英文完成推理和API调用，返回英文结果
- **小模型（Orchestrator）**：将英文结果翻译回Chinese/cloth-Chinese(如果需要)，回复用户
这样设计的好处是：

- 大模型专注做它擅长的事（推理），不需要担心多语言
- 小模型专注做它擅长的事（语言理解和生成），负责语言桥梁
- 整体系统既快又好

## 三、模型选择

### 3.1 Orchestrator模型选型：Qwen2.5-7B-Instruct

**候选模型：** 

1. Llama3-8B-Instruct
2. Gemma-2-9B-IT
3. Qwen2.5-7B-Instruct
4. deepseek-r1-7B

**最终选择Qwen2.5-7B的原因：**

1. Gemma-2-9B-IT对英文的倾向性较高，在服装专业中文下不稳定，常出现语言切换问题
2. Mistral-7B存在较强的语言漂移现象，需要复杂的prompt来避免，得不偿失
3. Llama3-8B的指令遵从较弱，经常输出格式错误，需要大量后处理
4. 矬子里挑大个：Qwen在tool call的时候频繁将字段翻译成汉语，但用prompt可以有效避免
6. 指令遵从能力强：Orchestrator调用MCP tools时，需要严格按照格式输出，Qwen的指令遵从能力在我们测试中最好，格式错误率Valid-Tool-Call Rate<3%；微平均 F1评估，Qwen-2.5-7B 相比 Llama-3-8B 高8%；
7. 意图识别准确：Qwen在意图分类任务上表现优秀，这是 Orchestrator 的核心能力
8. 再小的3B模型在工具调用的参数提取能力不够，主要体现在是复杂的日期、金额解析
9. 以 JSON Schema + 约束解码 + 校验-修复链保障工具调用 >97% valid；格式类错误自动修复 ≤2 次


TODO:: 这里大模型到底选什么呢啊
https://zhuanlan.zhihu.com/p/27168677478

### 3.2 复杂Sub-Agent模型选型：Qwen2.5-72B

**候选模型：**

qwen2.5:72b
Llama3-70B-Instruct
Mixtral-8x22B-Instruct
DeepSeek-V3（太大，放弃）
最终选择Mixtral-8x22B的原因：

推理能力强：Mixtral的MoE（Mixture of Experts）架构在复杂推理任务上表现优秀
自建评测基准，复杂诊断任务上 Mixtral-8x22B 的多步推理 Exact Match@K 比Llama3-70B-Instruct高10%
指令遵从能力强：复杂Sub-Agent需要严格按照推理链的格式输出，Mixtral在这方面表现最好
我们需要模型输出类似：Step 1: Call API X → Result Y → Analysis Z → Step 2: ...
未tune的Mixtral的格式正确率>95%，Llama3只有80%左右
成本可控：虽然是22B x 8 experts，但实际激活参数只有44B+shard，推理成本比真正的70B模型低30%
在A100上，Mixtral的p95延迟比Llama3-70B快20%
英文推理质量高：因为我们只用它处理英文任务，Mixtral在英文上的表现非常出色
Llama3-70B在多步推理的中间步骤常会"跳步"，逻辑不够严密
Mixtral在这方面表现更好，可能是MoE架构的优势，不同的expert负责不同的推理步骤



## 四、模型微调 - GRPO方法的实战应用

### 4.1 Orchestrator微调准备

- **1. 早期SFT**:构建1500条SFT对优化对话询问/确认用语一致性、专业词汇完整性，SFT阶段预热，且数据可以复用到GRPO中
- **2. GRPO**：任务不是简单的"输入→输出"，而是需要模型在多个可能的回复中选择最优的
  - 比如 Orchestrator 在识别意图时，可能有多个合理的 MCP tools/Sub-Agent 可以调用，我们需要模型选择最优的
  - SFT 阶段无法教模型"在这些选项中选最好的"
- **3. 数据效率**：GRPO 不需要昂贵的人工偏好标注（不需要 Preference Pairs），只需要定义reward函数
  - 不需要大规模标注偏好数据
  - GRPO 可以用现有的标注数据+自动化 reward，大大降低成本
- **4. 最终效果**：GRPO 微调后，Orchestrator路由准确率 70.1%→ 88.4%

### 4.2 Orchestrator微调记录

#### 4.2.1 数据构建
需要高质量的对话数据，包含：

- 用户输入（中文/服装专业/英语）
- Orchestrator 应该给出的自然语言响应
- Orchestrator 应该调用哪个 Sub-Agent
- 具体调用参数

**数据来源：**

- **公司内部协调流程**：从XXX的后台系统、邮件系统中获取了6000+脱敏订单对话流程
  - 内容包含真实用户的问题和查询的结果
  - 将其转换为训练数据
- **标注流程**：
  - Step 1：拆分订单信息至最小邮件内容回复
  - Step 2：AI+人工标注意图类别
  - Step 3：标注 MCP tools/Sub-Agent
  - Step 4：代码插入 SFT 阶段的数据需要 Orchestrator 应该给用户的初始响应
- **服装专业词汇 code-switching数据增强**：
  - 使用大学和行业通用服装专业教材，共生成500+样本，确保模型对code-switching的鲁棒性

**最终话题分布均匀处理后的数据集：**

- 训练集：3,000条
- 验证集：350条
- 测试集：150条


#### 4.2.2 数据清洗tricks
**trick1：过多的冗长对话导致训练数据噪声**

在邮件沟通过程中，有过多的与关键信息无关的对话，如果直接用这些数据训练，模型回学到错误的模式，并且无法做到高信息密度


**解决方案：**

- 构建了一个"精简总结模拟器"
- 分析更容易有冗长对话的对话风格，例如邮件开头结尾问候语句，公司信息名片，专业语言缩写识别错误，相同内容信息多次重复等
- 构建 无意义-noise 仿真集（中文/英文/专业语句/专业缩写 各2000），噪声注入训练把 Orchestrator 的路由 micro-F1 从 81.2%提升到 90.9%
- 用闭源大模型修正信息总结内容，并在训练数据的用户输入部分中，注入10%的错误
- 这样模型训练时就见过这些错误，推理时遇到专业缩写等错误也能正确理解

**效果：**

- Orchestrator路由准确率从92.4%提升到98.4%

**trick2：解决意图标注不一致问题**

比如：「我的订单怎么还没到？」

- 可能1：标注为order_status_query_by_owner（简单查询）
- 可能2：标注为order_issue_diagnosis（复杂问题）


这种不一致性导致模型困惑。

**解决方法：**

**1. 建立决策树规则库：**
**- 定义清晰的判断标准：**
  - 如果用户只是问"状态"→ 简单查询
  - 如果用户说"出了什么问题"、"为什么"→ 复杂问题
- 多轮专家审核：将不一致的样本进一步审查，给出标准答案
**- 主动学习：**
  - 用已训练的模型预测新数据
  - 找出模型不确定的样本（预测概率<0.7）
  - 优先标注这些样本，形成正向循环


### 4.2.3 GRPO 训练策略

Reward函数设计：

$$ R = 0.3 \times R_{router}  +0.4 \times R_{chat} +0.3 \times R_{evidence}$$





这是 GRPO 的核心。我设计了一个复合reward：

1. 路由准确性 reward（30%）：
  - 如果模型选择的 Sub-Agent 与标注一致 → +1
  - 否则 → -1
2. 精准程度 reward（40%）：
  - 对专业词汇识别的准确性，问题内容汇总
  - 匹配 → +1
  - 不匹配 → -1
3. 关联性惩罚reward（30%）：
  - 我们希望 Orchestrator 的响应必须要有完整的证据关联
  - 无证据关联 → -1
  - 与标注关联一致  → +1 

**训练超参数：**
```
学习率：3e-6
Batch size：32
LoRA rank：32
LoRA alpha：64
Epochs：4
优化器：AdamW
```

**关键调参经验：**

学习率调整:
- 一开始用了5e-6（常见的微调学习率），发现模型出现"灾难性遗忘"
- 具体表现：微调初期模型的专业词汇能力明显退化，很容易产生多余专业词汇
- 分析原因：我们的训练数据中专业词汇占比太高，学习率太高导致模型忘记了预训练的多语言知识
- 解决：降低学习率到3e-6，并且冻结 embedding 层，保持多语言稳定性
- LoRA rank选择：
  - 试过rank=16，发现容量不够，路由准确率只有88%
  - 增加到rank=32，准确率提升到94%
  - 试过rank=64，没有进一步提升，但训练时间增加50%，所以还是用32的模型
- 训练epochs：
  - 训练了4个epochs
  - 第3个epoch后，验证集reward基本收敛
  - 第4个epoch略有提升（+1.2%），但边际收益递减
  - 没有继续训练更多epochs，防止过拟合

**最终效果：**
- 路由准确率：78%（base model）→ 94%（fine-tuned）
- 精准程度：60%（base）→ 91%（fine-tuned）
- 关联性占比：62%（base）→ 95%（fine-tuned）

### 4.3 简单 Sub-Agent 微调详解

#### 4.3.1 数据构建
简单Sub-Agent的任务是工具调用，所以数据格式是：

```
Input: 用户问题（包含专业词汇/中文/英文）
Output: API调用序列（JSON格式）
```

**数据来源：**

标准查询/问询任务日志：
- 从后台系统中提取了1,500+条标准查询的日志
- 从邮件系统中提取了1,000+条询问记录
- 包含15个API：
  - get_user_by_orderID
  - get_orderID_by_styleID
  - get_status_by_orderID
  - get_projects_by_user
  - get_user_info
  - ...

API文档：
- 每个API都有详细的文档，包括参数说明、返回格式等
- 我们需要让模型理解这些文档，正确调用API

合成数据：
- 用 Deepseek R1 生成了额外1,000+条合成样本
- 覆盖边缘情况，如缺失参数、参数格式错误等

#### 4.3.2 数据清洗的坑和解决方案

**API参数提取不准确**

模型偶尔提取错误的参数，尤其是日期、大小写+特殊符号订单号等实体。
比如：

- 用户：「帮我查下AW25-KFWTS101/AW25-KFWTT173/INDOT26919--SUNWAY PU SW149222--大货面料订单」
- 模型应该提取：order_name=['AW25-KFWTS101','AW25-KFWTT173','INDOT26919']
- 但模型经常提取成：order_name="AW25-KFWTS101/AW25-KFWTT173/INDOT26919--SUNWAY PU SW149222"（分词错误，订单号和专业词汇识别错误）


**解决方案：**

- 引入实体识别预训练
- 用5,000条专门标注的NER（Named Entity Recognition）数据，先让模型学会提取订单号，款号，专业词汇等实体
- 然后再训练工具调用任务
- 结合NER+约束解码+参数校验器，这样模型的参数准确率从30%提升到96%


#### 4.3.3 GRPO 训练策略

Reward函数设计：

$$ R = 0.5 \times R_{call}  +0.5 \times R_{params} $$

- 工具调用准确性reward（50%）：
  - 如果模型选择的API正确 → +1
  - 否则 → -1
- 参数正确性reward（50%）：
  - 检查每个参数是否正确提取
  - 正确参数占比 = 正确数/总数，高于 90% → +1
  - 否则 → -1

**训练超参数：**
```
学习率：5e-6（比 Orchestrator 略高）
Batch size：32
LoRA rank：16（任务相对简单）
LoRA alpha：32
Epochs：3
```

**关键调参经验：**
**为什么学习率更高？**

- 简单Sub-Agent的任务更专注：只做工具调用，不需要复杂的对话管理
- 而且我们主要微调英文工具调用能力，不太担心破坏多语言能力
- 所以可以用更高的学习率，加快收敛
- 为什么LoRA rank更小？
  - 工具调用任务相对简单，不需要太大的capacity
  - rank=16已经足够，更大的rank会导致过拟合

**最终效果：**

- API调用成功率：68%（base model）→ 92%（fine-tuned）
- 参数准确率：85%（base）→ 96%（fine-tuned）
- 内部测试：简单查询成功率92%（500条）


### 4.4 复杂Sub-Agent微调详解
这是三个微调任务中最难的一个。

#### 4.4.1 数据构建
复杂Sub-Agent需要多步推理，所以数据格式是：

```
Input: 复杂问题（英文）
Output: 推理链（Chain of Thought）+ API调用序列 + 结论
```

**数据来源：**

- 复杂诊断案例：
  - 从长邮件，延期项目案例中提取了 500+个复杂问题
  - 这些都是简单 Sub-Agent 无法处理的，需要多流程负责人参与的案例
  - 比如：货期延期、订单数量异常、风控问题等
- 标注推理链：
  - 我们需要标注每个案例的完整推理过程：
  - 第1步：应该查什么API？
  - 第2步：根据结果，应该怎么分析？
  - 第3步：接下来应该查什么？
  - ...
  - 最后一步：得出结论
  - 由于人员较少，但复杂流程较为固定，由我和业务员筛选处理数据
- 合成推理链：
  - 用 DeepSeek R1 生成了额外2,000+条合成推理链
  - 提供5-10个真实案例作为 Few-shot examples
  - 大模型生成的质量还不错，但需要人工review

**最终数据集：**
- 训练集：2,500条
- 验证集：300条
- 测试集：100条

#### 4.4.2 数据清洗的坑和解决方案

**坑1：推理链标注成本极高**

前面提到，人工标注推理链耗时2周。即使这样，我们也只标注了200+个案例。这对于微调一个大模型来说，数据量还是偏少。

**解决方案 - 迭代标注策略：**

- 第一轮：人工标注 200 个高质量案例
- 第二轮：用这 200 个案例微调一个初步的模型
- 第三轮：用这个初步模型生成剩余案例的推理链
- 第四轮：人工审核和修正这些生成的推理链
- 第五轮：用修正后的全量数据重新微调
- 这个迭代策略大大降低了标注成本。第三轮生成的推理链，虽然不完美，但给标注员提供了很好的起点，他们只需要修正，而不是从头写。这样标注效率提升了3倍。

**坑2：推理链逻辑跳跃**
很多标注的推理链存在逻辑跳跃，缺少中间步骤。

比如：

```
Step 1: 查询订单状态 → status = "step line 1,2,3"
Step 2: 查询订单原计划信息  → status = "step line 1,2,3"
Step 3: 对比海外快递信息 → 不匹配，延期
结论：海外快递延误导致延期
```

这里跳过了很多步骤：

- 为什么订单时间节点和计划不匹配， 就只看海外快递时间节点？
- 有没有检查：前期沟通、样板出货、大货信息确认等时间节点
- 有没有检查订单内款号是否有更改等

这种跳跃会导致模型学到"捷径"，而不是完整的推理过程.

**解决方案 - 推理链完整性检查器：**

我设计了一个自动化工具：

- 分析每个推理链，识别可能的跳跃步骤
- 标准：
  - 每次节点对比，必须要有明确的对比总结
  - 每个API调用，必须有明确的理由（为什么调用这个API？）
  - 结论必须基于所有API调用的结果，对比内容必须基于邮件对话内容
  - 如果检测到跳跃，自动标记，需要自行补充
- 效果：
  - 推理链的平均步骤密度从3.8提升到7.2（更详细）
  - 模型训练后，推理的逻辑完整性明显提升


**坑3：部分案例结论错误**

有些案例，推理过程看起来很合理，但结论是错的。

比如：

- 推理链说"样板未确定"
- 但实际上是相关人员已确定，但未用确定等关键字

这种错误样本会严重误导模型。

**解决方案 - 真值验证流程：**

- 回溯验证：
  - 对于每个标注邮件信息，我们根据原邮件信息
  - 检查实际发生了什么，最终的描述方式是什么样的
  - 如果标注的结论与实际不符，剔除该信息
- 标准化定义：
  - 对于含糊不清的邮件信息，需要标准化用语
  - 要求负责人在关键节点审核标准化关键字
  - 确保每个案例的准确性
- 效果：
  - 剔除了18%的错误案例
  - 虽然数据量减少了，但质量大大提升
  - 模型训练后，诊断准确率从62%提升到78%


#### 4.4.3 GRPO 训练策略

**Reward函数设计：**

$$ R = 0.4 \times R_{correctness}  +0.3 \times R_{completeness} +0.3 \times R_{Summary}$$

- **推理正确性reward（40%）：**
  - 最终结论是否正确
  - 正确 → +1，错误 → -1
- **步骤完整性reward（30%）：**
  - 推理链是否完整，没有跳跃
  - 用启发式规则检查：每个API调用之间是否有分析步骤
  - 完整度分数：0-1 
- **语义总结和关键字reward（30%）：**
  - 语义总结和关键字是否一一对应
  - 理想情况：对实际的邮件内容进行确定信息总结
  - 正确 → +1，错误 → -1



**训练超参数：**


```
学习率：1e-6（大模型更敏感）
Batch size：16（显存限制）
LoRA rank：64（大模型需要更大rank）
LoRA alpha：128
Epochs：2（计算成本高）
```


TODO::大模型的需要确定哦
**关键调参经验：**

- **学习率必须更低：**
  - Mixtral-8x22B是一个非常强大的预训练模型
  - 如果学习率太高，容易破坏预训练知识
  - 我们试过3e-6，发现模型退化，推理能力下降
  - 降低到1e-6后，稳定提升
- **LoRA rank必须更大：**
  - 这是一个重要的坑！
  - 一开始我们用了rank=32（和小模型一样）
  - 结果发现，微调后模型的多步推理能力反而下降了
  - 分析原因：大模型的复杂推理能力需要更大的capacity来保存
  - 增加到rank=64后，问题解决，多步推理能力显著提升
- **提前停止策略：**
  - Mixtral-8x22B训练比较慢，但好在数据集比较小
  - 我们设置了提前停止：如果验证集reward连续5次没有提升，就停止
  - 实际训练了2个epochs后，reward基本收敛
  - 没有继续训练，避免过拟合



**最终效果：**
- 复杂问题解决率：45%（base model）→ 78%（fine-tuned）
- 推理链完整性：62%（base）→ 91%（fine-tuned）
- API调用效率：58%（base）→ 83%（fine-tuned）

# 五、关于知识图谱的构建

### 5.1 构建知识图谱查询的需求

由于没有使用企业级的用户管理系统，邮件系统的表头，表位，邮件主题均为有效信息，所以我构建了一套知识图谱用语用户信息，信息系统来进行数据查询

### 5.2 Graph的技术选型

**技术选型：**
- 模型选择：Qwen3-max
- 图数据库选择： Neo4j
- 框架选择：llm-graph-builder

**选择原因：**
- 模型选择 Qwen3-max 原因：
  - Token 数量支持较好（最大1M），可以完整保存邮件主题内容，用于查询证据提供
  - 分析能力完整，可以正确识别邮件表头，尾部的用户信息，关联信息
  - 在 function calling 方面能力出众，可以保证知识图谱的构建
- 图数据库选择 Neo4j 原因：
  - 擅长挖掘数据间的关系、路径和网络，符合订单流程长链路的网络记录
  - 并发要求不需要太高，避开 Neo4j的短板
  - 有相对应的官方配套框架方便进行快速写入和读取
- 框架选择 llm-graph-builder 原因：
  - 配合官方 Neo4j 使用方便
  - 在配置节点和关系的内容上简单，可通过配置直接读取
  - 文档全面，且有各种接入示例


### 5.3 最终结果

- 图谱构建：
  - 员工资料库
  - 公司体系关系库
  - 订单关系库
  - 邮件内容关联库
- 需求满足：Neo4j社区版只作为第一版知识图谱，用于暂时信息库进行查询已满足要求
- 定期更新：可定期用邮件系统和后台部分内容进行知识图谱更新

# 六、总结

这个项目现在已经稳定运行。我主要负责整个 Agent 智能层的设计、开发、微调、部署和知识图谱的构建、包括：

1. 创新的双层 Agent 架构：Orchestrator + Sub-Agent，平衡响应速度与推理能力
2. 差异化模型选型：Qwen2.5-7B（小模型）+ Mixtral-8x22B（大模型）协同工作
3. GRPO 微调方法：成功微调3个模型，显著提升任务表现
4. 信息查询的知识图谱 所有数据筛选，构建工作